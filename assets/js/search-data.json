{
  
    
        "post0": {
            "title": "Estimating Groundwater Elevation with Machine Learning",
            "content": "In this post I will demonstrate the efficacy of using machine learning to estimate groundwater elevation at monitoring wells across Los Angeles, California. The project proposal, data used, and detailed methods can be found in the final.ipynb notebook . The main focus will be comparing the performance of multiple linear regression with a random forest model. The data used in this project is from the California Water Boards&#39; GeoTracker. . Import libraries and data . | Basic data exploration . | Multiple linear regression . | Random forest . | 1. Import libraries and data . import numpy as np import pandas as pd import geopandas as gpd import matplotlib.pyplot as plt import sklearn.model_selection as ms import sklearn.linear_model as lm from sklearn.ensemble import RandomForestRegressor import sklearn.metrics as metrics . data . WID GW_MEAS_DATE LATITUDE LONGITUDE DEPTH ELEVATION WATER_ELEVATION PRCP TMAX TMIN . 0 T0603708316-MW-3 | 2010-01-03 | 34.046948 | -118.309659 | 97.64 | 201.16 | 103.52 | 0.0 | 261.0 | 122.0 | . 1 T0603708316-MW-5 | 2010-01-03 | 34.047051 | -118.309538 | 96.78 | 200.30 | 103.52 | 0.0 | 261.0 | 122.0 | . 2 T0603708316-MW-7 | 2010-01-03 | 34.046879 | -118.309237 | 96.86 | 200.36 | 103.50 | 0.0 | 261.0 | 122.0 | . 3 T0603708316-MW-4 | 2010-01-03 | 34.046936 | -118.309568 | 97.02 | 201.22 | 104.20 | 0.0 | 261.0 | 122.0 | . 4 T0603708316-MW-1 | 2010-01-03 | 34.046786 | -118.309321 | 97.66 | 201.51 | 103.85 | 0.0 | 261.0 | 122.0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 280473 SL204CP1893-MW3 | 2022-06-30 | 33.881710 | -118.219151 | 52.41 | 63.96 | 11.55 | 0.0 | 289.0 | 172.0 | . 280474 SL204CP1893-MW2 | 2022-06-30 | 33.881350 | -118.219306 | 51.83 | 62.89 | 11.06 | 0.0 | 289.0 | 172.0 | . 280475 SL204CP1893-MW1 | 2022-06-30 | 33.881410 | -118.219139 | 52.46 | 63.14 | 10.68 | 0.0 | 289.0 | 172.0 | . 280476 SL204AF1745-GMW-8 | 2022-06-30 | 33.878426 | -118.142977 | 25.12 | 62.24 | 37.12 | 0.0 | 289.0 | 172.0 | . 280477 SL204AF1745-GMW-9 | 2022-06-30 | 33.878422 | -118.143241 | 25.13 | 62.30 | 37.17 | 0.0 | 289.0 | 172.0 | . 280478 rows × 10 columns . First we import the necessary libraries and data. The data is stored in a csv file and is read into a pandas dataframe. Above we can see the first and last five rows of the dataframe. The data consists of a well ID (WID) measurement data (GW_MEAS_DATE), latitude (LATITUDE), longitude(LONGITUDE), groundwater depth (DPETH), well elevation (ELEVATION), groundwater elevation (WATER_ELEVATION), precipitation (PRCP), and temperature minimum (TMIN) and maximum (TMAX) for each sample. . The dependent variable will be DEPTH and the independent variables are the GW_MEAS_DATE, ELEVATION, LATITUDE, LONGITUDE, PRCP, TMIN and TMAX. . 2. Basic data exploration . The first step in any data science project is to explore the data. This is done to get a better understanding of the data and to identify any issues that may need to be addressed. I will start by looking at a correlation matrix to see if there are what types of linear relationships are present within the independent variables and then I will look the distribution of the dependent variable, WATER_ELEVATION. . Text(0, 0.5, &#39;Water Elevation (ft)&#39;) . Now I will look at the spatial distribution of the data. I want to see what the average groundwater depth is across LA county. I will do this by creating a scatter plot of the data and coloring the points by the average groundwater depth. I will also add a colorbar to the plot to show the depth range. I will also plot the boundaries of LA county to see where the data is located. . C: Users chief AppData Local Temp ipykernel_24800 609258529.py:5: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry. for polygon in la: C: Users chief AppData Local Temp ipykernel_24800 609258529.py:17: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry. for polygon in la: . We can see that there is seemingly not a large spatial correlation between the groundwater depth and the location of the wells. However there does seem to be a correlation between the groundwater elevation and the location of the wells. This may make it easier to get a higher explained variance score for groundwater elevation, but not neccesarily improve the root mean squred error. This could be due to the fact that the groundwater elevation is a function of the groundwater depth and the well elevation. Theoretically there shouldn&#39;t be a huge difference in the overall performance of the model, and is a good example of why looking purely at explained variance is not sufficent in determining the accuracy of a model. . Next I will look at a correlation matrix of the variables to see if there are any obvious linear relationships between the variables. Removing independent variables that are highly correlated with each other is a good idea because it will reduce the number of variables in the model and will reduce the chance of overfitting. . GW_MEAS_DATE LATITUDE LONGITUDE DEPTH ELEVATION WATER_ELEVATION PRCP TMAX TMIN . GW_MEAS_DATE 1.000000 | 0.038650 | -0.012340 | 0.166829 | 0.073478 | 0.046942 | -0.002186 | 0.089086 | 0.096333 | . LATITUDE 0.038650 | 1.000000 | -0.406199 | 0.342657 | 0.809210 | 0.787293 | 0.029642 | -0.023140 | -0.021120 | . LONGITUDE -0.012340 | -0.406199 | 1.000000 | -0.089412 | -0.289506 | -0.287665 | -0.015964 | -0.012132 | -0.009427 | . DEPTH 0.166829 | 0.342657 | -0.089412 | 1.000000 | 0.353408 | 0.190039 | 0.021543 | 0.009229 | 0.007821 | . ELEVATION 0.073478 | 0.809210 | -0.289506 | 0.353408 | 1.000000 | 0.985583 | 0.014541 | -0.009103 | -0.011224 | . WATER_ELEVATION 0.046942 | 0.787293 | -0.287665 | 0.190039 | 0.985583 | 1.000000 | 0.011364 | -0.011223 | -0.013194 | . PRCP -0.002186 | 0.029642 | -0.015964 | 0.021543 | 0.014541 | 0.011364 | 1.000000 | -0.227470 | -0.092061 | . TMAX 0.089086 | -0.023140 | -0.012132 | 0.009229 | -0.009103 | -0.011223 | -0.227470 | 1.000000 | 0.689391 | . TMIN 0.096333 | -0.021120 | -0.009427 | 0.007821 | -0.011224 | -0.013194 | -0.092061 | 0.689391 | 1.000000 | . Above we see that there are some mild linear realationships between a few independent variables, but nothing strong enough to support removing them. For the dependent variable, there is not a very strong relationship to any of the independent variables which may hint at the fact that a linear model may prove to be insufficent. . 3. Multiple linear regression . Now that I have a better understanding of the data, I will move on to building the models. First I will try a multiple linear regression model and then I will try a random forest model. I will use the explained variance score and root mean squared error (RMSE) to evaluate the performance of the models. The explained variance score, as the same suggests is a metric that tells us how much of the variation in the dependent variable can be explained with the independent variables. The RMSE will tell us in similar units (in this case feet), how far away on average our predictions are from the true values. For example, an explained variance score of 0.25 means the model can account for 25% of the variation of the dependent variable, and an RMSE of 55 means that on average the model&#39;s predictions are within 55 feet of the true value. The data will be split 80/20 into training and testing sets. The training set will be used to train the model and the testing set will be used to evaluate the model. . Multiple Linear Regression - Depth Explained Variance: 0.14574251300684116 Root Mean Squared Error: 46.71178742352509 . We can see that the multiple linear regression model has an explained variance score of 0.14 and an RMSE of 45.962. This is not a very good score, but it is a good starting point. . 4. Random forest . Now that we know a linear model will not sufficently model the data, I will try a random forest model. I will use the same 80/20 training and testing split as the multiple linear regression model. I will also use the same evaluation metrics as the multiple linear regression model. First I will run the default hyperparameters and then I will tune the hyperparameters to see if I can improve the model. For optimization I will be using a hyperparameter gridsearch with 5-fold cross validation. The hyperparameters I will be tuning are the number of trees in the forest (n_estimators), the maximum depth of the tree (max_depth), the minimum number of samples required to split an internal node (min_samples_split), and the minimum number of samples required to be at a leaf node (min_samples_leaf). I will be using the default options for the rest of the hyperparameters for the random forest model. . Random Forest Regressor: default Explained Variance: 0.9964212619588727 Root Mean Squared Error: 2.9874245983847123 . Above we see the results from the default random forest regressor model. We can see that the explained variance score is 0.994 and the RMSE is 3.811. This is a significant improvement over the multiple linear regression model. Next I will perform a hyperparameter gridsearch to see if I can improve the model. Due to previous experience with tuning this model, I have an idea for the ranges I want to test for each hyperparameter. In total I will be testing 162 combinations of hyperparameters with 5 fold cross validation, totalling 810 fits. I will be testing the following ranges for each hyperparameter: . &#39;n_estimators&#39;: [100, 150, 200] | &#39;bootstrap&#39; : [True, False] | &#39;max_depth&#39;: [None, 150, 200] | &#39;min_samples_leaf&#39;: [1, 3, 6] | &#39;min_samples_split&#39;: [2, 4, 6] | . Fitting 5 folds for each of 162 candidates, totalling 810 fits . Random Forest Regressor: {&#39;bootstrap&#39;: True, &#39;max_depth&#39;: 150, &#39;min_samples_leaf&#39;: 1, &#39;min_samples_split&#39;: 4, &#39;n_estimators&#39;: 100} Explained Variance: 0.9891225335964102 Root Mean Squared Error: 5.220190642619172 . As shown above, the best combinations of hyperparameters were {&#39;bootstrap&#39;: True, &#39;max_depth&#39;: 150, &#39;min_samples_leaf&#39;: 1, &#39;min_samples_split&#39;: 4, &#39;n_estimators&#39;: 100}. We can see that the overall performance is not much better than the default model. The explained variance score is 0.989 and the RMSE is 5.220. This is a very good score, but it is not much better than the default model. This may be due to the fact that the default model is already very good. However parameter tuning in a random forest model, while not always necessary, can be very useful in improving the model as well as reducing the chance of overfitting. In the future I would like to try a different model, such as a neural network, to see if I can improve the model further. It would also be interesting to see if adding some more independent variables could improve the model. Things like the soil type, better precipitation and temperature data, and proximity to pumping stations and the output of those pumping stations could be useful in improving the model. . While in this case I trained the model on only Los Angeles, it would be useful to train it on a dataset for the entire state of California. This would allow the model to be used for other counties in California. Being able to accurately estimate groundwater depth is very useful for many applications, such as water management, water quality, and water supply. .",
            "url": "https://aarongaines.github.io/intro_datasci_blog/2022/09/04/Final-Project.html",
            "relUrl": "/2022/09/04/Final-Project.html",
            "date": " • Sep 4, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://aarongaines.github.io/intro_datasci_blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://aarongaines.github.io/intro_datasci_blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://aarongaines.github.io/intro_datasci_blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://aarongaines.github.io/intro_datasci_blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}